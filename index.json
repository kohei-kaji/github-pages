
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Hi! I’m Kohei Kajikawa, a phd student at NINJAL. My research interests include computational linguistics and computational psycholinguistics.\nWe effortlessly understand the meaning of a sentence as we see or hear it. I’m interested in how linguistic knowledge, such as grammar, is algorithmically employed during this process (CogSci 2024).\nAnd, I’m curious about why language structures are the way they are. Specifically, I aim to investigate the extent to which communicative efficiency can explain syntactic structures (CoNLL 2024).\n文を見たり聞いたりするとすぐにその意味がわかりますが、その際に、無意識下でどのような形の文法がどのようなアルゴリズムで使われているのか関心があります。\nまた、その文法が、なぜいまある形になっているのかについても気になっており、特に、「使用のしやすさ」の観点からどれだけ説明が可能か調べています。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi! I’m Kohei Kajikawa, a phd student at NINJAL. My research interests include computational linguistics and computational psycholinguistics.\nWe effortlessly understand the meaning of a sentence as we see or hear it. I’m interested in how linguistic knowledge, such as grammar, is algorithmically employed during this process (CogSci 2024).\nAnd, I’m curious about why language structures are the way they are. Specifically, I aim to investigate the extent to which communicative efficiency can explain syntactic structures (CoNLL 2024).\n","tags":null,"title":"Kohei Kajikawa","type":"authors"},{"authors":["梶川 康平"],"categories":null,"content":"","date":1741996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741996800,"objectID":"061d99297b8acf55e5ebc8fa795b6dcf","permalink":"https://kohei-kaji.github.io/github-pages/misc/nlp-2025/","publishdate":"2025-03-15T00:00:00.254693Z","relpermalink":"/github-pages/misc/nlp-2025/","section":"misc","summary":"『自然言語処理』の学会記事","tags":[],"title":"計算心理言語学の新地平開拓の試み：効率的なコミュニケーション仮説の検証","type":"misc"},{"authors":["磯野 真之介","梶川 康平","杉本 侑嗣","浅原 正幸","大関 洋平"],"categories":null,"content":"","date":1741824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741824000,"objectID":"8090096a68f123e44043ed9f60a8e1b3","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/isono-etal-2025-nlp/","publishdate":"2025-03-03T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/isono-etal-2025-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"CCGによる日本語脳波データのモデリング","type":"domestic_conference"},{"authors":["赤間 美香","梶川 康平","大関 洋平"],"categories":null,"content":"","date":1741824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741824000,"objectID":"4877174264bfef955700c1997477fb34","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/akama-etal-2025-nlp/","publishdate":"2025-03-03T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/akama-etal-2025-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"統語情報は脳情報デコーディングに寄与するのか？","type":"domestic_conference"},{"authors":["吉田 遼","磯野 真之介","梶川 康平","染谷 大河","杉本 侑嗣","大関 洋平"],"categories":null,"content":"","date":1741651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741651200,"objectID":"a7739c231eb762cb2694716ff5dbb7b2","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/yoshida-etal-2025-nlp/","publishdate":"2025-03-03T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/yoshida-etal-2025-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"アテンションが記憶想起の認知モデルたりうるならば、記憶の表現としては何が妥当か？","type":"domestic_conference"},{"authors":["中石 海","吉田 遼","梶川 康平","福島 孝治","大関 洋平"],"categories":null,"content":"","date":1741651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741651200,"objectID":"6783e5e2e5d96cc030e95a4762fc20e9","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/nakaishi-etal-2025-nlp/","publishdate":"2025-03-03T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/nakaishi-etal-2025-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"自然言語における冪則と統語構造の関係の再考","type":"domestic_conference"},{"authors":["梶川 康平","磯野 真之介","窪田 悠介","大関 洋平"],"categories":null,"content":"","date":1741651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741651200,"objectID":"7dc90d3f30aea126c85c8b70633d1bb0","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/kajikawa-etal-2025-nlp/","publishdate":"2025-03-03T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/kajikawa-etal-2025-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"認知負荷の最適化戦略としての自由語順と項省略","type":"domestic_conference"},{"authors":null,"categories":null,"content":" 確率や情報理論といった数学の道具は、言語使用や言語の構造それ自体を支配している何らかの規則を記述するのに非常に有用であるように思えます。\nそれは、確率や情報理論といったものは現象に対して理論中立的 (theory-neutral) な記述が可能で、とにかく使い勝手が良い道具だからなのかもしれないし、そもそも人間の言語処理をはじめとした認知活動が何らかの確率的なものだからなのかもしれないし、認知活動自体が、ベイジアンが主張するような「合理的 (rational)」なものだと考えたら合理的でありそう、という直感や経験的事実があるからなのかもしれないし…。\nいずれにせよ、確率や情報理論は、言語処理・言語使用の研究（つまり、Performance の側面の研究）、そしてさらには言語の構造や知識自体の研究（つまり、Competence の側面）をするのに非常に強力な道具です。\n近年は、コーパスをはじめとした言語資源の整備、計算機の性能向上やプログラミング言語・各種計算ライブラリの充実、大規模言語モデルのような汎用的な言語処理技術たちの登場によりかなりの精度で言語の情報量が推定できるようになってきたこと、といったさまざまな要因たちが揃ってきて、そしてさらには、確率や情報理論といった道具自体の理論研究や言語研究へ応用するといった方法論が確立されてきたので、これからできることが大量にあるよ、という状況です。\n実際、心理言語学とか、計算言語学、計算心理言語学、認知科学とか言われる分野の研究をみていると（これらの分野がそれぞれどういった範囲を指しているのか正直よくわからないが）、確率や情報理論であふれています。 昨年、2024年夏にオランダのロッテルダムであった CogSci（認知科学の国際会議）に参加したら、これが私にとって初めての海外での国際会議だったわけですが、何とまあ端から端まで情報理論かベイジアンモデリングで割と衝撃を受けました。 そういった状況が良いか置いておいて、とりあえず勉強しなきゃなぁと思わされたし、この波に乗っておきたい、と思えました。ので、その紹介記事です。\nこのあたりのレビュー論文、本として、個人的参照すべきものたち：\n確率を取り入れた言語研究は結構有用じゃないでしょうか、という話： Chater and Manning (2006) 言語を含めた認知科学における確率モデル的（合理的）アプローチについて： Tenenbaum et al. (2006) Griffiths et al. (2010) Perfors et al. (2011) Griffiths et al. (2024) Griffiths (2024) 目次 文処理系 Surprisal Lossy-context surprisal Noisy-channel model 効率的なコミュニケーション 単純性と情報伝達性のトレードオフ Ferrer i Cancho and Sole (2003) Rational Speech Act (RSA) Uniform Information Density (UID) Dependency Length Minimization (DLM) Memory–prediction trade-off 言語獲得 Xu and Tenenbaum (2007) Perfors et al. (2011) Abend et al. (2017) 言語進化 繰り返し学習モデル (Iterated Learning Model) 文処理系 Surprisal ある単語 $w$ の生起確率 $P(w)$ の 負の対数 $-\\log P(w)$ のことを単語 $w$ のサプライザルと呼びます。 サプライザル理論 (Hale, 2001; Levy, 2008b) では、ある単語の予測のしにくさ（サプライザル）はその単語の処理の難しさに比例する、とします： \\begin{equation} \\text{difficulty}(w)\\propto -\\log P(w) \\end{equation}\n確率値を表すときは大文字 $P$、確率分布を表すときは小文字 $p$ を使うようです。 対数の底はしばしば $2$ で bit単位ですが、底が一致している限りはサプライザル同士の相対関係は変わらないので、底の値自体をサプライザルの定義に組み込む必要は（たぶん）ないです。 $\\log_2 x = \\frac{\\log_e x}{\\log_e 2} = \\frac{\\log_e x}{0.30103…}$ と、底の変更は可能。 サプライザルの値 $-\\log P(\\cdot)$ は、生起確率 $P(\\cdot)$ の値が小さければ小さいほどほど大きくなる、という関係になっています。\nそして、実際に、読み時間 (e.g., Demberg and Keller, 2008; Smith and Levy, 2013; Wilcox et al., 2023; Shain et al., 2024) や、ERP（事象関連電位）(e.g., Frank et al., 2015; Brennan and Hale, 2019)、 fMRIによるBOLD信号 (e.g., Lopopolo et al., 2017; Shain et al., 2020) について、サプライザルが predictor として有効であることが示されています。\nサプライザルがとらえているものは何なのか？ では、単語 $w$ の生起確率 $P(w)$ は何で求めることができるのでしょうか。 逐次的な文処理過程について考える場合、単語 $w$ 以前の文脈 $w_1,\\dots,w_{n-1}$ が与えられたときの単語 $w$ の生起確率 $P(w\\mid w_1,\\dots,w_{n-1})$ が求められれば良い、すなわち、言語モデルがあれば良い、ということになります。\nHale (2001) では、言語モデルとして、確率的文脈自由文法（Probabilistic Context-Free Grammar, PCFG）によるものを採用しました。 PCFGは、文脈自由文法における各文法規則に生起確率を割り当てたものです。詳しくは、自然言語処理系においてとりあえず最初に参照すべき文献である Jurafsky and Martin (2025, Appendix C) を参照ください。\n$P(w_n\\mid w_1,\\dots,w_{n-1})$ は、条件付き確率の定義により、 \\begin{equation} P(w_n\\mid w_1,\\dots,w_{n-1}) = \\frac{P(w_1 \\cdots w_{n-1}, w_n)}{P(w_1 \\cdots w_{n-1})} \\end{equation} と分解することができます。\nPCFGは、文脈自由性により、ある文字列に対する可能なすべての木構造は互いに排反なので、以下が成り立ちます： \\begin{equation} P(w_1 \\cdots w_n) = \\sum_{T\\in\\mathcal{T}(w_1 \\cdots w_n)} P(T, w_1 \\cdots w_n) \\end{equation}\nまた、PCFGは木構造と文字列の生成モデルであり、木構造 $T$ に対して文字列 $w_1\\cdots w_n$ が一意に定まるので、 \\begin{equation} P(w_1 \\cdots w_n\\mid T) = 1 \\end{equation} が成り立ちます。\nよって、ある文字列 $w_1\\cdots w_n$ の確率は、その文字列に対するすべての可能な木構造の確率の和に等しくなります： \\begin{align} P(w_1 \\cdots w_n) \u0026amp;= \\sum_{T\\in\\mathcal{T}(w_1 \\cdots w_n)} P(T, w_1 \\cdots w_n) \\newline \u0026amp;= \\sum_{T\\in\\mathcal{T}(w_1 \\cdots w_n)} P(T)\\cdot P(w_1 \\cdots w_n\\mid T) \\newline \u0026amp;= \\sum_{T\\in\\mathcal{T}(w_1 \\cdots w_n)} P(T) \\end{align}\nつまり、サプライザル $-\\log P(w_n\\mid w_1,\\dots,w_{n-1})$ は、 \\begin{align} -\\log P(w_n\\mid w_1,\\dots,w_{n-1}) \u0026amp;= -\\log\\frac{P(w_1 \\cdots w_{n-1}, w_n)}{P(w_1 \\cdots w_{n-1})} \\newline \u0026amp;= -\\log\\sum P(n\\text{単語までの木構造}) \\newline \u0026amp;\\quad - \\log\\sum P(n-1\\text{単語までの木構造}) \\end{align} と、$n$ 単語時点での構造に関する情報量と $n-1$ 時点での構造に関する情報量の差、言い換えると、その単語により構造に関してどれだけ情報が得られたのか、を表す値として説明されます（解説として、Hale (2016) も参照ください）。\nHale (2001) でPCFGが採用されたのは、$n$-gram 言語モデルでは（$n$ がとりわけ大きいわけではなければ）単語間の依存関係を正しく取り扱えないからであり、さらにはそもそも著者自身の興味が文法構造の処理にあったからだと思われるのですが、それにより、シンボリックで離散的な文法理論を、連続的で柔軟な情報理論を通して、処理負荷の予測につなげられています。\n* そのため、Hale (2006) では、PCFG ではなく、linguistically-motivated な Minimalist Grammar を用いてモデリングを行っています。構造への確率が付与できさえすれば良いので、そういった拡張が容易にできます。\nこれに対し、Levy (2008b) では、特定の構造・意味の形を前提としない形でのサプライザルの解釈を提示しました。\nアイディアは非常にシンプルで、$n$ 時点での単語 $w_n$ のサプライザルを、　$n-1$ 時点までの意味 $T\\in\\mathcal{T}$ の確率分布から $n$ 時点での意味の確率分布へのKL距離（Kullback–Leibler divergence）、すなわち、単語 $w_n$ の入力により、意味に関する確率分布がどれだけ変化するのかを示す値である、と示しました。 これは、先ほどの Hale (2001) でのサプライザルの導出過程と同じで、$P(w_1,\\cdots,w_n\\mid T) = 1$ 、という仮定を置いた場合に示すことができます： \\begin{align} \u0026amp;D_{\\textit{KL}}(p(T\\mid w_1\\cdots w_{n})\\parallel p(T\\mid w_1\\cdots w_{n-1})) \\newline \u0026amp;= \\sum_{T\\in\\mathcal{T}} p(T, w_1\\cdots w_n)\\log\\frac{p(T\\mid w_1\\cdots w_n)}{p(T\\mid w_1\\cdots w_{n-1})} \\newline \u0026amp;= \\sum_{T\\in\\mathcal{T}} p(T, w_1\\cdots w_n)\\log\\frac{\\frac{p(w_n\\mid T, w_1\\cdots w_{n-1})p(T\\mid w_1\\cdots w_{n-1})}{p(w_n\\mid w_1\\cdots w_{n-1})}}{p(T\\mid w_1\\cdots w_{n-1})} \\newline \u0026amp;= …","date":1740960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740960000,"objectID":"753872ff72719dae30ddefb003d15bf0","permalink":"https://kohei-kaji.github.io/github-pages/blogs/250303information/","publishdate":"2025-03-03T00:00:00Z","relpermalink":"/github-pages/blogs/250303information/","section":"blogs","summary":"確率モデル・情報理論を使った心理言語学・計算心理言語学研究について","tags":null,"title":"確率・情報理論を使った言語研究","type":"blogs"},{"authors":["梶川 康平"],"categories":null,"content":"","date":1738368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738368000,"objectID":"1e5322e3f3b76a492ab1564b153cb6a8","permalink":"https://kohei-kaji.github.io/github-pages/misc/%E8%A8%80%E8%AA%9E%E5%AD%A6%E3%83%95%E3%82%A7%E3%82%B9-2025/","publishdate":"2025-02-01T06:07:27.373591Z","relpermalink":"/github-pages/misc/%E8%A8%80%E8%AA%9E%E5%AD%A6%E3%83%95%E3%82%A7%E3%82%B9-2025/","section":"misc","summary":"言語学フェス2025 / オンライン","tags":[],"title":"言語の起源はコミュニケーションか?：計算心理言語学の観点から","type":"misc"},{"authors":["Kohei Kajikawa"],"categories":null,"content":"","date":1738108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738108800,"objectID":"d9f765cbdd6b003890155f4a8ae557da","permalink":"https://kohei-kaji.github.io/github-pages/talks/nlp-colloquium/","publishdate":"2025-01-12T06:07:27.373591Z","relpermalink":"/github-pages/talks/nlp-colloquium/","section":"talks","summary":"NLPコロキウム / オンライン","tags":[],"title":"Is Structure Dependence Shaped for Efficient Communication? A Case Study on Coordination","type":"talks"},{"authors":["Kohei Kajikawa","Yusuke Kubota","Yohei Oseki"],"categories":null,"content":"","date":1731628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731628800,"objectID":"ea8e3d15c8f3aed30523184e0b23b53f","permalink":"https://kohei-kaji.github.io/github-pages/international_conference/kajikawa-etal-2024-conll/","publishdate":"2024-09-26T06:07:27.373591Z","relpermalink":"/github-pages/international_conference/kajikawa-etal-2024-conll/","section":"international_conference","summary":"","tags":[],"title":"Is Struncure Dependence Shaped for Efficient Communication? A Case Study on Coordination","type":"international_conference"},{"authors":["Kohei Kajikawa","Ryo Yoshida","Yohei Oseki"],"categories":null,"content":"","date":1720051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720051200,"objectID":"e3b23b1f949b12f2446ab2e68680389c","permalink":"https://kohei-kaji.github.io/github-pages/international_conference/kajikawa-etal-2024-cogsci/","publishdate":"2024-07-04T06:07:27.33591Z","relpermalink":"/github-pages/international_conference/kajikawa-etal-2024-cogsci/","section":"international_conference","summary":"Computational psycholinguistics has traditionally employed a complexity metric called Node Count, which counts the number of syntactic nodes representing syntactic structures and predicts processing costs in human sentence processing. However, Node Count does not dissociate distinct syntactic operations deriving those syntactic structures, so that how much processing cost each syntactic operation induces remains to be investigated. In this paper, we introduce a novel complexity metric dubbed Composition Count, which counts the number of syntactic operations deriving syntactic structures, allowing us to understand the computational system of human sentence processing from the derivational, not representational, perspective. Specifically, employing Combinatory Categorial Grammar (CCG) which is equipped with multiple syntactic operations and thus suitable for the purpose here, we investigate (i) how much distinct syntactic operations of CCG contribute to predicting human reading times, and (ii) whether the same holds across languages. The results demonstrate that distinct syntactic operations of CCG have independent and cross-linguistic contributions to predicting human reading times, while Node Count turns out not to be robust cross-linguistically. In conclusion, these results strongly suggest the importance of Composition Count to dissociate distinct syntactic operations, not whole syntactic representations, and understand the computational system of human sentence processing.","tags":[],"title":"Dissociating Syntactic Operations via Composition Count","type":"international_conference"},{"authors":["磯野 真之介","梶川 康平","大関 洋平"],"categories":null,"content":"","date":1719619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719619200,"objectID":"fcc47590da66bed36c0ddc57d41cfe33","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/isono-etal-2024-lsj/","publishdate":"2024-06-29T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/isono-etal-2024-lsj/","section":"domestic_conference","summary":"逐次的な文理解においては、統語的関係にある語句の線形位置が離れている場合、作業記憶への負荷（局所性効果）が生じると考えられる。予測される局所性効果は、採用する文法理論によって異なるが、Isono (2024) は、組合せ範疇文法（CCG）を採用することで、動詞先置型言語と後置型言語における局所性効果のパターンを統一的に説明しうることを示し、さらに英語コーパスの読み時間を予測できることを統計的に示した。これを踏まえ本研究では、日本語のコーパスに自己ペース読文による読み時間を付した大規模データセット（BCCWJ-SPR2）を用いて、CCGが日本語における局所性効果を予測できるかを検証した。線形混合効果モデルによる分析の結果、CCGに基づく距離の効果がスピルオーバー領域において観察され、この効果は従来の主流である依存文法に基づく距離の効果よりも安定していることが示された。","tags":[],"title":"日本語大規模読み時間コーパスにおける記憶の負荷のCCGによるモデリング","type":"domestic_conference"},{"authors":null,"categories":null,"content":" \u0026lt;工事中\u0026gt;\n自然言語の形態論・統語論を考えるとき、それらがどの程度「複雑」なのかを考えることは、言語理論を考えるのにも、人間の文産出・理解について考えるのにも、そして言語進化について考えるのにも極めて重要だと思います。 そして、自然言語の文法の「複雑さ」（以降、適当に「文法」といってしまいます）について、形式言語の世界では「生成力」という概念での整理がなされており、言語学研究としてきちんと扱いたいと個人的に思っています。\n生成力とは？ 「生成力（generative capacity）」とは、文法の「複雑さ」の概念です。 ここでの複雑さは、その文法が作る（生成する）ことのできる文字列もしくは木構造の種類をもとに定義されます。 ここで、文字列に関する生成力を「弱生成力 (weak generative capacity)」と、木構造に関する生成力を「強生成力 (strong generative capacity)」と呼びます (Chomsky, 1965; 福井・辻子, 2017; 日本語訳)。\n弱生成力は、ある文法が作ることのできる文字列（単語の配列）の集合に関する概念で、文法の弱生成力が等しいかつ語彙が等しい言語同士では、作ることのできる文字列の集合は完全に一致します。 つまり、弱生成力の議論において、文法とは、「容認可能な文字列のみを受理し、容認不可能な文字列は排除する装置」のことを意味します。 チョムスキー階層（下図。図はJager and Rogers (2012)より。）という概念は、弱生成力のクラス分けに関するものです（Chomsky (1956); Chomsky and Schutzenberger (1963)）。\n自然言語の弱生成力の議論に関しては、\nJager and Rogers (2012) Hunter (2020) Roger Levyの計算心理言語学の授業のWeek 7 あたりが良かったです。\n強生成力は、ある文法が作ることのできる木構造の集合に関する概念であり、Chomsky自身は弱生成力ではなく強生成力を研究の対象とするべし、としました。 木構造は（ほぼすべての理論において）意味や韻律の理論と直接関わるので、単に容認可能な文字列を識別する装置を考えるのでは不十分だ、ということでしょう。 ただ、強生成力それ自体に明確な定義があるわけではなく、そのために理論ニュートラルな議論が難しくなっている、というのが現状です（形式言語理論の世界だと、単純にある言語クラスにおいて作ることのできる木構造の集合について考えれば良く、本来ならば、理論言語学の言語理論についても同様のことができるはずですが、残念ながら多くの言語理論は、その木構造の集合を定義することができるほど厳密ではないように思えます。もちろん、以下で紹介する範疇文法理論やMinimalist Grammarなどの形式性と記述的妥当性の両面をちゃんと追い求めている文法理論たちを除いて）。 私が知らないだけかもしれませんが、Chomskyを中心とした主流生成文法においても、強生成力の議論がなされている、というイメージはないです。\nもちろん、強生成力についての議論はまったくないわけではなく、最近では、CCGとTAGが弱生成力だけではなく、強生成力においても等価である、と主張されています (Schiffer and Maletti, 2021)。 （生成力が同一となると、最後はどちらの derivation step がより妥当か、という話になる。）\n文脈自由文法 (Context-Free Grammar) 自然言語の構造について考えるとき、 文脈自由文法とは、$(\\Gamma, \\Sigma, S, R)$ の4つ組で定義されます。\n$\\Gamma$: 非終端記号（非端末記号）の有限集合 $\\Sigma$: 終端記号（端末記号）の有限集合で、$\\Gamma\\cap \\Sigma=\\varnothing$ $\\mathit{S}\\in \\Gamma$: 開始記号 $R$: 規則（生成規則）の有限集合。各規則は、$\\alpha\\rightarrow\\beta$ の形をとる。ここで、$\\alpha\\in\\Gamma$ はちょうど1つの非終端記号、$\\beta$ は $(\\Gamma\\cup\\Sigma)^*$ の任意の列（空列を含む）であり、$\\rightarrow$ は左側の要素から右側の要素への書き換えを意味します。 「文脈自由」とは、書き換え対象はただ1つの非終端記号だけであり、他の要素から影響を受ける（書き換えに文脈が存在する）というわけではないことに由来します。 これにより、ネストした構造を表現することができるので、たとえば四則演算はまさに文脈自由文法でしょう。\n反復補題 ある言語が文脈自由ではないことは、以下の（文脈自由文法の）反復補題を使うことで示すことができる：\n文脈自由言語 $L$ には、長さが $m$ 以上の文字列 $w$ があり、これは適当な $w, v, x, y, z\\in\\Sigma^*$ によって $w=uvxyz$ で表すことができる。ここで、この $w$ は以下の3つの条件を満たす：\n任意の $i\\geq 0$ に対して、$uv^ixy^iz\\in L$ $|vy|\\geq 1$ $|vxy|\\leq m$ 例として、$L = {a^nb^nc^n\\mid n\\geq 0}$ が文脈自由言語であるのかこの反復補題を用いて考えてみましょう。\n他の文法形式との等価性 projective dependency tree 依存構造木において、依存関係同士が「交差」しないものを projective なtreeであるといいます。 文脈自由文法で表現できる依存関係は、projectiveな依存関係にとどまることが知られています。\nAB grammar 範疇文法 (Categorial Grammar) において、関数合成しかない範疇文法は、文脈自由文法とその弱生成力が等価です。\n自然言語は文脈自由文法で扱えるのか？ では、自然言語の文法は、文脈自由文法で表現することはできるのでしょうか。\nここで、しょうもないですが大事な注意として、「文脈自由文法で表現することはできるのか？」という問いは、Chomsky (1957) で指摘されているように、「文法が有限個」という前提を置いた上でのものです。 というのも、観測したすべての自然言語の文を「記述」したいと思ったとき、高々それらの文と同数の文法規則さえ用意することができれば、それは、文脈自由文法どころか有限状態オートマトンで「記述」したことになります。\nたとえば、projectiveな依存構造と文脈自由文法が等価ですが、依存構造が交差するとき、すなわち、non-projectiveであるとき、その構造は文脈自由文法では記述できません。 では、依存構造が交差する状況は自然言語に存在するのでしょうか？\nrespectively読み こうした議論の中で、最初に（？）議論の俎上に上がったのが「respectively読み」でしょう。 図で示すように、日本語でも「それぞれ」をはさんで、主語と述語の依存関係が交差し（文字列で表すと、$a_1 b_1 a_2 b_2$ のようなコピー言語になり）、まさに文脈自由文法では記述的ないものになります。\nこの現象は割とわかりやすいためか、今でも時々自然言語の文脈自由文法による記述の非妥当性を示す例として紹介されがちなのですが、実は、Pullum and Gazdar (1982) により否定されています。 彼らの主張は至極単純で、respectively読みは単に統語の問題ではなく意味の問題でしょう、というものです。\nExtraction 一方で、extraposition from NPやheavy NP shift、scramblingといった構文は、分析の仕方にも依りますが、非常に文脈依存性を感じるところではないでしょうか。 Extraposition from NPとは、たとえば The man fell into the pit who had been chased by dogs. のような文で、ここで、The man とそこにかかる関係節 who … の間に動詞句 fell into the pit が入っている構造です。 Scramblingは、日本語でよくある、 花子に太郎が会った。 のような、名詞句の語順が通常と入れ替わった状態のものです。\nこうしたものも、Gazdar (1981) や Gazdar et al. (1985) によるGeneralized Context-Free Grammarにより記述可能であることが示されています。\nCross-serial dependency Shieber (1985) により、Swiss-German（ドイツ語のスイス方言）の従属節中には、統語的にcross-serial dependencies（連続交差依存）が成り立ち、これにより自然言語には文脈自由文法では作れない表現が存在することが示されました。\ncross-serial dependenciesとは、以下のような（ここでは連続する動詞と対応する主格の項）の依存関係が交差しあっている状況です（文は Shieber (1985) より）。\n非常に雑にいうと、依存関係が交差しないネストした（入れ子構造になっている）関係だと文脈自由文法で表現できるのですが、連続交差依存は文脈自由文法では表現できません。 たとえば、高校生の頃、英語を読むときに句や節ごとに括弧でかこんで読んでいた人は多いと思うのですが（そうですよね？）、いま考えてみると、これは英語を入れ子構造として、すなわち文脈自由レベルの文法として解析していたことになります。 もしSwiss-Germanを勉強することになっていたら、このような読み方はできなかったはずです。\ncross-serial dependenciesはそうあるわけではなく、上記の文と同じ意味を日本語で表そうとすると、以下のように、依存関係は交差せず、入れ子構造になります。 cross-serial dependencies自体は確かに頻度は多くはないですが (e.g., Ferrer i Cancho et al., 2018)、存在しないわけではないので、自然言語の文法を文脈自由文法で済ますのは不十分であるといえます。\nちなみに、同時期に Culy (1985) にて、Bambaraを用いて、形態的にも文脈自由文法で表現できない事例が存在することが示されています。\n241212追記：Bambaraの例は音調的な振る舞いに依存しており、形態論の問題なのか？、という議論があるようで、結局、アイヌ語にて形態論レベルでのbeyond context-freenessが示されたようです (Sanuma and Aizawa, 2024)。\ncross-serial dependency は日本語にあるのでしょうか。\nまた、Stabler (2004) では、英語においてもcross-serial dependenciesは存在している主張されています（画像はStabler (2004; p.701) より）。\nまた、正規言語で自然言語を語るのはさすがに厳しそうに思われますが、文脈自由文法は実際に自然言語の記述に広く使われています。 例えば、Penn Treebank (Marcus et al., 1993) はまさに文脈自由文法によるアノテーションであり、多言語に拡張されているところを見る限り、（実用上）大きな問題は生じていないようです。 同様に、Universal Dependencies (UD) (Nirve et al., 2020) においても、（依存関係が交差していない木 …","date":1711065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711065600,"objectID":"7b5915374016743b821dcc9bb5a408f5","permalink":"https://kohei-kaji.github.io/github-pages/blogs/240322mcsg/","publishdate":"2024-03-22T00:00:00Z","relpermalink":"/github-pages/blogs/240322mcsg/","section":"blogs","summary":"自然言語の文法とその生成力に関する話。弱文脈依存文法 (Mildly Context-Sensitive Grammar) について、など。","tags":null,"title":"弱文脈依存文法にまつわる理論言語学のはなし","type":"blogs"},{"authors":["梶川 康平","窪田 悠介","大関 洋平"],"categories":null,"content":" ","date":1710288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710288000,"objectID":"8116fd9a3f563fc6b606e48f41d2964e","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/kajikawa-etal-2024-nlp/","publishdate":"2024-03-17T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/kajikawa-etal-2024-nlp/","section":"domestic_conference","summary":"自然言語には合成性にもとづく統語構造が存在し、さらに統語構造を直接変形する操作（統語変形）が存在する。先行研究において、合成性はコミュニケーションと学習可能性に関する圧力のトレードオフとして創発することが示されている。しかしながら、自然言語になぜ統語変形が存在するのかは明らかではない。本研究では、統語変形を必要とする統語現象として等位接続に注目した上で、統語変形もまたコミュニケーションと学習可能性に関する圧力のトレードオフとして創発するのかを検証する。","tags":[],"title":"統語変形はコミュニケーションから創発するのか？","type":"domestic_conference"},{"authors":["梶川 康平","窪田 悠介","大関 洋平"],"categories":null,"content":"","date":1705708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705708800,"objectID":"22d978018640e96a2f8359230f2a39e4","permalink":"https://kohei-kaji.github.io/github-pages/misc/%E8%A8%80%E8%AA%9E%E5%AD%A6%E3%83%95%E3%82%A7%E3%82%B9-2024/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/misc/%E8%A8%80%E8%AA%9E%E5%AD%A6%E3%83%95%E3%82%A7%E3%82%B9-2024/","section":"misc","summary":"言語学フェス2024 / オンライン","tags":[],"title":"統語変換は文化進化から生じるのか？：等位接続構造での検討","type":"misc"},{"authors":["梶川 康平","窪田 悠介","大関 洋平"],"categories":null,"content":"","date":1705363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705363200,"objectID":"e14b4cefc42318ad3baa5e9da9c111a7","permalink":"https://kohei-kaji.github.io/github-pages/misc/ninjalsalon-2024/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/misc/ninjalsalon-2024/","section":"misc","summary":"第256回 NINJALサロン / 国立国語研究所 多目的室","tags":[],"title":"統語変換はコミュニケーションから創発するのか？","type":"misc"},{"authors":["中石 海","吉田 遼","梶川 康平","福島 孝治","大関 洋平"],"categories":null,"content":"","date":1701993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701993600,"objectID":"cd68461d47d069815e39ba3e281661bb","permalink":"https://kohei-kaji.github.io/github-pages/misc/mims-2023/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/misc/mims-2023/","section":"misc","summary":"2023年度　MIMS 現象数理学研究拠点 共同研究集会「社会物理学とその周辺」","tags":[],"title":"自然言語の統語構造における相互情報量の解析と数理モデル化","type":"misc"},{"authors":["Kohei Kajikawa"],"categories":null,"content":"","date":1700352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700352000,"objectID":"8af8e142ea91ddd3630a9141b6ba9c4e","permalink":"https://kohei-kaji.github.io/github-pages/international_conference/kajikawa-2023-lenls/kajikawa-2023/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/international_conference/kajikawa-2023-lenls/kajikawa-2023/","section":"international_conference","summary":"In the Japanese cleft construction, multiple noun phrases (NPs) can occupy the focus position even if they do not form a `constituent` in the mainstream generative grammar. However, a single NP with the nominative case marker *ga* cannot. Kubota and Smith (2006, 2007) analyze the cleft construction with Combinatory Categorial Grammar (CCG, Steedman, 1996, 2000; Baldridge, 2002), but their analysis overgenerates a *ga*-marked NP in the focus position. Indeed, they recognized the obligatory omission of the nominative case marker in that position, and they assumed that some independently motivated principles should explain the distribution. However, it would be better if the distribution could be explained within the grammar formalism. This study aims to address this issue by partially incorporating the idea of *constructivist* analysis of argument structure from the mainstream generative grammar Kratzer (1996) into the CCG framework. Furthermore, I will show that this revision correctly predicts two syntactic phenomena where the *ga*-marked NP behaves differently from other case marked NPs.","tags":[],"title":"Analyzing Japanese Cleft Construction in Combinatory Categorial Grammar","type":"international_conference"},{"authors":["梶川 康平"],"categories":null,"content":" ","date":1680048000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680048000,"objectID":"8e7fe67ea15594b62bbc339281e748f9","permalink":"https://kohei-kaji.github.io/github-pages/misc/ewfl8-2023/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/misc/ewfl8-2023/","section":"misc","summary":"Encouraging Workshop on Formal Linguistics 8 (EWFL8) / 東京大学 駒場キャンパス 18号館","tags":[],"title":"CCGによる日本語文処理のモデリング","type":"misc"},{"authors":["梶川 康平","吉田 遼","大関 洋平"],"categories":null,"content":" ","date":1678924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678924800,"objectID":"37dd6e92e60b68f4cc2e75c96c792d28","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/kajikawa-etal-2023-nlp/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/kajikawa-etal-2023-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"CCGによる日本語文処理のモデリング","type":"domestic_conference"},{"authors":["磯野 真之介","梶川 康平","吉田 遼","大関 洋平"],"categories":null,"content":"","date":1678752000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678752000,"objectID":"cf73a7ced5115d924acd806a235404c7","permalink":"https://kohei-kaji.github.io/github-pages/domestic_conference/isono-etal-2023-nlp/","publishdate":"2024-01-11T06:07:27.373591Z","relpermalink":"/github-pages/domestic_conference/isono-etal-2023-nlp/","section":"domestic_conference","summary":"","tags":[],"title":"極小主義に動機づけられた統語的教示に基づく言語モデル","type":"domestic_conference"},{"authors":null,"categories":null,"content":"生成文法理論の１つであるCCG（組合せ範疇文法）を、私は文法理論としても、そして文処理のモデリングの道具としても非常に有用なものであると考えていますが、残念ながら（分野によっては）人口に膾炙しているとは言い難い状況ですので、CCGの広まりを願い、ここに文献リストや参照したら良いであろう情報を記します。\n文献案内 さらっと雰囲気を掴みたい場合 Jurafsky and Martin (to appear) NLPの教科書として有名なDan Jurafsky氏とJames Martin氏による Speech and Language Processing のDraftのAppendixの１つ。 最低限の組合せ規則と、CCGによるチャートパーザが簡潔に説明されている。 言語学の方でも、前半だけ読むと、CCGにどういう文法操作があるのか・どういう構造を作るのか何となく掴みやすいのではないか。 Steedman (2022) Mark Steedman氏による、網羅的なCCGの解説論文。本をギュッと圧縮したイメージ。 CCG分析で特徴的な構文や関連トピックについて最低限の紙幅で説明されてる。 私ははじめ、これと、ここで引用されている文献を行き来して勉強した。 Clark (2021, arXiv) C\u0026amp;C parserのStephen Clark氏によるCCGのparsingに関する論文。 後半部分は当時最新のCCG parser作りに関する話だが、前半は、CCGの理論やCCGのparsingの概説・歴史解説として読める。 理論言語学関係 統語・意味の理論としてのCCGを理解したい場合に参照すべき文献たちです。 その他、CCGには音韻の理論としての顔もありますが、そのあたりは詳しくないので含めていません（Steedman (2000) にはそのあたりも載っています）。 Steedman (1996) CCG本の最初。 LI Monographs。100ページ強。 CCGで、英語を網羅的に記述できることを示すべく書かれたもの。 Steedman (2000) Steedman (1996) の強化版。 若干の理論的改訂あり。 Google Scholarでは出版年が誤って2001となっており、ちらほら Steedman (2001) として論文中に登場してしまう。 Baldridge (2002) Jason Baldridge氏による博論。 slash typingを導入し、言語理論としてのCCGを大きく進化させた。 slash type については、Baldridge and Kruijff (2003; EACL)も参照。 Steedman (2000) までと違い、等位接続を文法規則 ではなくconjunctのカテゴリ X\\X/X で導出。 博論なので、解説としても有用。 戸次 (2010) 日本語CCG本。 日本語文法の論文としても面白い。 特に活用体系や、量化子周りの話。 書評 (矢田部, 2011) も面白い。 Steedman and Baldridge (2011) 非常に簡潔にまとまったCCGの解説論文。 そのため、Steedman (1996)や(2000)と並んでしばしば引用されている。 （CCGを引用したいくらいなら、本を読むのは大変なので、こちらを読んで引用した方が良さそう。） Non-Transformational Syntaxという本の1チャプター。 この本はほかの章も良い。Sag and Wasowの章が好き。 Steedman (2023) ほとんどミニマリストに向けて書いてあるLIの論文。 ミニマリストの理論を踏まえ、「CCGならもっと簡潔に書けますよ」と主張したもの。著者の穏健な姿勢が窺える。 ミニマリストがCCGをはじめる際には一番わかりやすいと思われる（自分がミニマリストではないのでわからないが）。 Steedman (to appear) Mark Steedman氏によるCCG本のドラフト。 機械の文処理関係 ここでの機械の文処理とは、文を入力とし、確率的に計算した構文木を返してくれる構文解析器等のことです。 Clark and Curran (2007; CL) C\u0026amp;C parserとして有名。 CCGbankを使った最初のwide-coverage parser。 いまだに現役だったりする。Supertaggerの評価用としてよく見る。 Supertagとは、CCG含め、lexicalized theory of grammarの語彙範疇のこと。 通常のPOS tagよりも情報が豊富なので、supertagと呼ばれる。そして、supertagが決まればほとんど文の構造は決まるので、supertaggingはalmost parsingであるとも言われている (Bangalore and Joshi, 1999; CL)。 Hockenmaier and Steedman (2007; CL) 英語CCGbank。 空白なし小文字b Penn Treebank (WSJ) からの自動変換。　Lewis and Steedman (2014; EMNLP) EasyCCG として有名。 深層学習 + A* search。 Uematsu et al. (2013; ACL) 日本語CCGBank。 空白なし大文字B 係り受けコーパスである京都大学テキストコーパス（毎日新聞）からの自動変換。 日本語CCGBankの続きとしては、以下のようなものがあります。 Kubota et al. (2020; LREC) による ABCTreebank The Keyaki Treebank からの自動変換 Tomita et al. (2024; EACL) ABCTreebank と lightblue による日本語CCGBankの再構築 Noji and Miyao (2016; ACL) 日本語CCG parserの Jigg。 Martinez-Gomez et al. (2016; ACL) 意味解析システムの ccg2lambda。 Bekki and Kawazoe (2016; LNTCS) 日本語CCG parserの lightblue。 Yoshikawa et al. (2017; ACL) 日本語CCG parserの depccg。 人間の文処理関係 Ades and Steedman (1982; Linguist Philos) 一番最初のCCG論文。 当初より逐次的な文処理を意図して作っていることが明確で良い。 notationは今とところどころ異なる。 Demberg (2012; TAG+) CCGの逐次的な構造構築に関して、統語論・心理言語学の知見から（否定的に）述べられている。 CCGではfull incremental parseができない（英語の目的語関係節）。 full incremental parseを実現しようとDコンビネータを導入すると過剰生成する、という指摘。 Stanojevic et al. (2023; Cognitive Science) CCGによる、英語文処理（fMRIによるBOLD信号）のモデリング。 貢献は大きく分けて2つ。 CCGが、CFG（文脈自由文法）よりもより高い精度でBOLD信号を予測できることを示した。言語理論としてより妥当なCCGが、逐次的な文処理のモデル化においても優れていることを示した。 CCGの構造構築操作由来の予測子と、LLMで算出したsurprisal（文処理における強力な予測子）とは別にBOLD信号の予測に効いた。 Kajikawa et al. (2024; CogSci) 日本語と英語の視線計測データで、CCG内の理論的に異なる文法操作が、それぞれ心理的にも異なるものとして使われていることを示唆。 Isono (2024; Cognition) 文を逐次的に理解する際に起こる、短期記憶に由来する処理負荷を、CCGの木構造ベースで説明したもの。 貢献・面白い点は、短期記憶由来の処理負荷は、今まで簡単な文脈自由文法（記述力は妥当ではない）や依存文法（単語間関係の記述は優れているが、逐次的に構造がどう構築されるかは不明瞭）でしかなかったが、それをCCG (記述力が妥当かつ、構造構築過程も明確) に発展させたこと。 個人的に、CCGの良さは、単に「competence grammarのままでprocessingのことをちゃんと語れそうな理論」、ということだけではなく、「いろいろなことができすぎない理論」だと思っています。具体的に、ここでは、構成素同士の合成にちゃんと制限があって、必ずしも何でも組合せられるわけではないが（つまり、単語が順に入ってきたとき、毎度毎度その単語をすでに作っている構成素に統合できるとは限らない）、この論文では、その組合せられないポイントを証拠に人間の文処理が説明できることが経験的に示されています。 生成力関係 Vijay-Shanker and Weir (1994; Math. Systems Theory) CCGの弱生成力が、Linear-Indexed Grammar (LIG), Head Grammar (HG), Tree-Adjoining Grammar (TAG) と等価であることを示した。 Kuhlmann et al. (2015; CL) Vijay-Shanker and Weir (1994) のときに想定されていたCCGではなく、slash-typeを導入したCCGにて、TAGと弱生成力が等価であることを示した。 Schiffer and Maletti (2021; TACL) CCGの強生成力が、TAGと等価だと主張。 標準形関係 CCGでは、同じ意味を複数の異なる統語構造で表現することができます（spurious ambiguity; 擬似的曖昧性）。このおかげで、逐次的な合成による構造構築が可能なのですが、構造的曖昧性がなくとも構文木が一意に定まらないということなので、parserを作る上では問題になると考えられていました。 実際には、学習データのbranchingが一貫していれば、標準形の制約なしでも擬似的曖昧性の問題にはぶつからないようです (Yoshikawa et al. (2017; ACL), Yoshikawa et al. (2019; 自然言語処理) より)。 標準形の定義により、（構造的曖昧性がないとき）統語構造を１つに絞ることができます。 Eisner (1996; ACL) 証明に関する情報 可能な限り関数合成（function composition）を行わないという制限により、right-branchingな標準形を定義。 もちろん、逆の制限にすれば、left-branchingを標準形とすることもできる。 Hoyt and Baldridge (2008; ACL) Dコンビネータの導入と、それを含めた標準形の定義。 Hockenmaier and Bisk (2010; COLING) Eisner (1996; ACL)の拡張。 generalized compositionとgrammatical type-raisingを考慮した拡張。 CCG parserを触ってみよう！ CCGは、他の文法理論に比べ、高精度な構文解析器（parser）が数おおく整備されている、という点で非常に有用です。 semantic parsingに適度に使いやすいといったことや、ツリーバンクの整備が早かった、という点が要因な気がしています（当時を知らないので妄想です）。 特に、下記のparserたちは動かすのにそこまで難易度が高くないのでおすすめです。 そもそも構文解析器とはなんぞやという方へ 構文解析 自然言語 …","date":1673481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673481600,"objectID":"8d83490b81b832dee29d6a573515d42d","permalink":"https://kohei-kaji.github.io/github-pages/blogs/230112ccg/","publishdate":"2023-01-12T00:00:00Z","relpermalink":"/github-pages/blogs/230112ccg/","section":"blogs","summary":"CCG（組合せ範疇文法）に関する雑多な文献案内・parser案内など。","tags":null,"title":"CCGに関する情報集","type":"blogs"},{"authors":["Shinnosuke Isono","Takuya Hasegawa","Kohei Kajikawa","Koichi Kono","Shiho Nakamura","Yohei Oseki"],"categories":null,"content":"","date":1673417270,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673417270,"objectID":"1aa5b4480f702df4269eb12675167af7","permalink":"https://kohei-kaji.github.io/github-pages/international_conference/isono-etal-2022-lenls/isono-etal-2022/","publishdate":"2023-01-11T06:07:50.120137Z","relpermalink":"/github-pages/international_conference/isono-etal-2022-lenls/isono-etal-2022/","section":"international_conference","summary":"","tags":[],"title":"Formalizing Argument Structures with Combinatory Categorial Grammar","type":"international_conference"}]